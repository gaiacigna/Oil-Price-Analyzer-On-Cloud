{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73281e42-c455-49fa-9582-5d24794e8238",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"./images/Logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10b52b-9ab5-409a-848f-d1f6e506bec7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Oil Price Analyzer\n",
    "## A daily oil price analyzer and predictor\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "It consist in a software pipeline with the aim of visualize and predict the diesel and oil prices of roughtly 600 oil station situated in Catania, on a daily basis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219795b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# The structure\n",
    "\n",
    "The pipeline is based on different software, all dockerized, that collaborate passing data between each other and enriching it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4108ead-8a75-410a-88f8-66b2e661b825",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"./images/Pipeline.jpg\" width=\"70%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81a0e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Data Format\n",
    "\n",
    "Every morning the Italian Minister \"Ministero delle Imprese e del Made in Italy\" publishes the prices of oil and other fuels at 8 a.m. in a **csv** format. Furthermore, in the following <a href=\"https://www.mimit.gov.it/images/exportCSV/anagrafica_impianti_attivi.csv\">link</a>, a registry of the stations can be retrieved.\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "### Let's pay attention at the phrase above: \"[...] the prices of oil and other fuels at 8 a.m.\", **more on that later**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36917cc2-072f-45dc-9caf-b78597acdd5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Prezzi alle 8.csv\n",
    "\n",
    "Estrazione del 2023-07-24 <br>\n",
    "idImpianto;descCarburante;prezzo;isSelf;dtComu<br>\n",
    "3464;Benzina;2.255;0;21/07/2023 20:30:06<br>\n",
    "3464;Benzina;1.945;1;21/07/2023 20:30:06<br>\n",
    "3464;Gasolio;2.109;0;21/07/2023 20:30:06<br>\n",
    "...<br>\n",
    "...<br>\n",
    "...<br>\n",
    "56860;Benzina;1.859;1;22/07/2023 10:14:47<br>\n",
    "56860;Gasolio;1.689;0;22/07/2023 10:14:47<br>\n",
    "56860;Gasolio;1.689;1;22/07/2023 10:14:47<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d31cf71-7b0d-4a57-b828-ddfbcd9ab4ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Logstash\n",
    "\n",
    "Logstash is the software/technology chosen for the **Data Ingestion** section of the project. The choice was mainly made because of the easy of use and integration of its plugins, two in particular: **Http_poller input plugin**, and the other one we'll save it for later (again...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a86f6c-9a51-4819-820f-29abea2e65a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Http_poller input plugin\n",
    "\n",
    "This plugin makes everything easier when it comes to HTTP GET/POST request with a specific schedule, described for example by using a crontab format. \n",
    "\n",
    "Speaking of schedule, we now come to the main problem, earlier we said \"[...] the prices of oil and other fuels at 8 a.m.\" which (sadly) doesn't mean that the file gets uploaded at 8 a.m., it simply means that the price indicated in the csv file is the price of the fuel at 8 a.m. of the specific file's day.\n",
    "<br>\n",
    "\n",
    "**TL;DR**: there's not a specific time of the day at which the minister uploads the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722873d-049b-4619-9819-20d96f78a8a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# What's a scalable solution?\n",
    "\n",
    "# Request with one less of the nyquist rate frequency and deduplicate **somehow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d055484-e3dc-4680-883b-cb1e5846b950",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div align=\"center\"><img src=\"./images/memes/nyquist.jpeg\" width=\"50%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5381e99-a14c-43b2-9143-0446df21cf36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Logstash Filter Plugin - Fingerprint\n",
    "\n",
    "It's the second plugin used, mentioned above. It simply add a new field to each logstash message with the fingerprint of a field that already exists, using a specific fingerprint algorithm such as **sha256**.\n",
    "<br>\n",
    "\n",
    "This field will be crucial for **deduplication**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafcd79d-6776-4207-a21c-68389bf95d65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Final logstash file\n",
    "\n",
    "```\n",
    "input{\n",
    "    http_poller{\n",
    "        urls => {\n",
    "            prices => {\n",
    "                url => \"https://www.mimit.gov.it/images/exportCSV/prezzo_alle_8.csv\"\n",
    "                method => get\n",
    "            }\n",
    "        }\n",
    "        request_timeout => 60\n",
    "        schedule => { cron => \"0 */11 * * *\"} # crontab for each 11 hours\n",
    "        codec => \"csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "filter{\n",
    "    fingerprint{\n",
    "        method => \"SHA256\"\n",
    "        source => [\"event\"]\n",
    "        target => [\"hash\"]\n",
    "        key => \"taptap\"\n",
    "    }\n",
    "}\n",
    "\n",
    "output{\n",
    "    kafka{\n",
    "        bootstrap_servers => \"kafkaServer:9092\"\n",
    "        topic_id => \"prices\"\n",
    "        codec => \"json\"\n",
    "        message_key => \"%{hash}\"\n",
    "        max_request_size => 10485880\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5261de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Kafka\n",
    "Kafka is our **Data Streaming** tool. It ensures us that every message will get to destination no matter how bad things can get, and because of this it can surely handle some duplicated messages...\n",
    "\n",
    "# KRaft\n",
    "In order not to burden the pipeline too much, by adding for example another managing service like Zookeeper, **KRaft** is used to manage Kafka."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da5f1d-9278-4fe8-8a58-4720104955c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# The whole Kafka \"Situation\"\n",
    "\n",
    "<div align=\"center\"><img src=\"./images/memes/logstash to kafka.jpeg\" width=\"40%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ccd4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Spark\n",
    "**Spark** is the heart of the pipeline, by adding the logic and execution of a program that uses **pySpark**. Thanks to that, data are:\n",
    "- cleaned\n",
    "- deduplicated\n",
    "- daily enriched with prediction\n",
    "- every station's dataset gets updated\n",
    "- regressors retrain for the next day to increase accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ea36c-b7dc-48e4-a28b-2ff4849a6f4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Cleaning and deduplication\n",
    "\n",
    "As we mentioned before, there's a problem of duplicate messages. In order to solve this we leverage on the simpliest solution: **drop_duplicates**.\n",
    "\n",
    "It is a spark streaming dataframe function that, using a field name, it removes the rows with the same values: this fits perfectly with the **hash** field that logstash added for us before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a3155-5a9a-4861-bb21-58058435509a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div align=\"center\"><img src=\"./images/memes/deduplicate.jpeg\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a8285",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prediction\n",
    "\n",
    "A project goal is to predict the next day's prices for each station. \n",
    "\n",
    "To do so, each station has its own **Linear Regressor** in order to capture every price trend. \n",
    "\n",
    "After the prediction is added, each **\"dataset\"** of each station gets updated by adding the new price of the day and all the regressors gets **retrained** in order to get an accuracy improvements day-by-day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265b9db-320c-49be-b9b2-0a589a519e67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Problems? A lot.\n",
    "\n",
    "Using a regressor for each station though is a **resource challenge**. \n",
    "\n",
    "The \"regular\" way to do this would be a filter for each station and fuel, add the prediction to the single row and then \"union\" the row to a new dataframe that at the end would be an exact copy of the original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d682d-65e1-4db5-b177-0ddf950269c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"./images/memes/outofmemory.jpeg\" width=\"40%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d1b59e-2579-411f-af0e-da59e632a7f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# \"Solution\"\n",
    "\n",
    "<div aling=\"center\"><img src=\"./images/memes/pandas.jpeg\" width=\"40%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64f36a-6e91-485a-a915-bbd164967179",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark - Pandas - Parquet\n",
    "\n",
    "In truth the real solution has been offered by the compression of the **Apache parquet** format that can be used in RAM as a backend for the conversion from Spark Streaming Dataframe to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0102d4-8c0a-4575-b7ed-8010a5e2edbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Elasticsearch and Kibana\n",
    "\n",
    "Elasticseach is the **storage** of the pipeline, while Kibana is a **tool of visualization**. \n",
    "\n",
    "The choice was easy: they both belong to the **Elastic** group (with also Logstash). They're very integrated with each other and makes everything very easy to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120610f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

services:
  logstash:
    build: ./logstash/
    image: tap:logstash
    container_name: logstash
    environment:
      XPACK_MONITORING_ENABLED: false
      KAFKA_OUTPUT_BOOTSTRAP_SERVERS: kafkaServer:9092
      KAFKA_OUTPUT_TOPIC: prices
    networks:
      tap:
        ipv4_address: 10.0.100.10
    volumes:
      # - ./logstash/pipeline/http_poller_original.conf:/usr/share/logstash/pipeline/logstash.conf # original
      - ./logstash/pipeline/http_poller_simulation.conf:/usr/share/logstash/pipeline/logstash.conf #! for simulation
    depends_on:
      kafkaTopic:
        condition: service_completed_successfully
      spark:
        condition: service_healthy


  zookeeper:
    build: ./kafka/
    image: tap:kafka
    container_name: kafkaZK
    environment:
      - KAFKA_ACTION=start-zk
    networks: 
      tap:
        ipv4_address: 10.0.100.22


  kafkaServer:
    build: ./kafka/
    image: tap:kafka
    container_name: kafkaServer
    networks:
      tap:
        ipv4_address: 10.0.100.23
    ports:
      - 9092:9092
    environment:
      KAFKA_ACTION: start-kafka
    depends_on:
      - zookeeper


  kafkaTopic:
    build: ./kafka/
    image: tap:kafka
    container_name: kafkaTopic
    networks:
      - tap
    environment:
      KAFKA_ACTION: create-topic
      KAFKA_TOPIC: prices
      KAFKA_SERVER: kafkaServer:9092
    depends_on:
      - zookeeper
      - kafkaServer


  # kafkaUI:
  #   image: provectuslabs/kafka-ui:latest
  #   container_name: kafkaUI
  #   ports:
  #     - 8080:8080
  #   environment:
  #     KAFKA_CLUSTERS_0_NAME: local
  #     KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafkaServer:9092
  #     LOGGING_LEVEL_ROOT: error
  #     LOGGING_LEVEL_COM_PROVECTUS: error
  #   networks: 
  #     - tap
  #   depends_on:
  #     - kafkaServer


  spark:
    build: ./spark/
    image: tap:spark
    container_name: spark
    deploy:
      resources:
        limits:
          cpus: '8.0'
          memory: 6g
    networks:
      tap:
        ipv4_address: 10.0.100.27
    ports:
      - 4040:4040
    volumes:
      - ./spark/code/src/:/opt/code
    entrypoint: "/opt/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.elasticsearch:elasticsearch-spark-30_2.12:8.7.1 --master local[*] /opt/code/main.py"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4040"]
      interval: 10s
      timeout: 10s
      retries: 20
    depends_on:
      kafkaTopic:
        condition: service_completed_successfully


  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.7.1
    networks:
      tap:
        ipv4_address: 10.0.100.51
    environment:
      cluster.routing.allocation.disk.threshold_enabled: false
      cluster.name: elasticsearch
      discovery.type: single-node
      xpack.security.enabled: false
      bootstrap.memory_lock: true
      ES_JAVA_OPTS: -Xms1g -Xmx4g
    ports:
      - 9200:9200


  kibana:
    container_name: kibana
    image: tap:kibana
    build: ./kibana/
    networks:
      tap:
        ipv4_address: 10.0.100.52
    ports:
      - 5601:5601

  simulationServer:
    build: ./pythonSimulation
    image: tap:simulationServer
    container_name: simulationServer
    ports:
      - 7777:7777
    networks:
      tap:
        ipv4_address: 10.0.100.77
    depends_on:
      kafkaTopic:
        condition: service_completed_successfully



networks:
  tap:
    name: tap
    driver: bridge
    ipam:
      config:
        - subnet: 10.0.100.0/24
